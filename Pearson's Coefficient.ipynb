{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required modules.\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing excel sheet of original rankings.\n",
    "Topsis = pd.read_excel(\"Fuzzy_TOPSIS_Ranking.xlsx\")\n",
    "Topsis_lst = Topsis.iloc[:,-1].to_list()\n",
    "AHP = pd.read_excel(\"AHPRanking.xlsx\")\n",
    "AHP_lst = AHP.iloc[:,-1].to_list()\n",
    "Concordance = pd.read_excel(\"Concordance Ranking.xlsx\")\n",
    "Concordance_lst = Concordance.iloc[:,-1].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of weightages:  41\n",
      "\n",
      "\n",
      "                     Inc 5%  Inc 10%  Dec 5%   Dec 10%\n",
      "Weightage Increased                                   \n",
      "1                       1.0      1.0     1.0  1.000000\n",
      "2                       1.0      1.0     1.0  1.000000\n",
      "3                       1.0      1.0     1.0  1.000000\n",
      "4                       1.0      1.0     1.0  1.000000\n",
      "5                       1.0      1.0     1.0  1.000000\n",
      "6                       1.0      1.0     1.0  1.000000\n",
      "7                       1.0      1.0     1.0  1.000000\n",
      "8                       1.0      1.0     1.0  1.000000\n",
      "9                       1.0      1.0     1.0  1.000000\n",
      "10                      1.0      1.0     1.0  1.000000\n",
      "11                      1.0      1.0     1.0  1.000000\n",
      "12                      1.0      1.0     1.0  1.000000\n",
      "13                      1.0      1.0     1.0  1.000000\n",
      "14                      1.0      1.0     1.0  1.000000\n",
      "15                      1.0      1.0     1.0  1.000000\n",
      "16                      1.0      1.0     1.0  1.000000\n",
      "17                      1.0      1.0     1.0  1.000000\n",
      "18                      1.0      1.0     1.0  1.000000\n",
      "19                      1.0      1.0     1.0  1.000000\n",
      "20                      1.0      1.0     1.0  1.000000\n",
      "21                      1.0      1.0     1.0  1.000000\n",
      "22                      1.0      1.0     1.0  1.000000\n",
      "23                      1.0      1.0     1.0  1.000000\n",
      "24                      1.0      1.0     1.0  1.000000\n",
      "25                      1.0      1.0     1.0  1.000000\n",
      "26                      1.0      1.0     1.0  1.000000\n",
      "27                      1.0      1.0     1.0  1.000000\n",
      "28                      1.0      1.0     1.0  1.000000\n",
      "29                      1.0      1.0     1.0  1.000000\n",
      "30                      1.0      1.0     1.0  1.000000\n",
      "31                      1.0      1.0     1.0  1.000000\n",
      "32                      1.0      1.0     1.0  1.000000\n",
      "33                      1.0      1.0     1.0  1.000000\n",
      "34                      1.0      1.0     1.0  1.000000\n",
      "35                      1.0      1.0     1.0  1.000000\n",
      "36                      1.0      1.0     1.0  0.998701\n",
      "37                      1.0      1.0     1.0  1.000000\n",
      "38                      1.0      1.0     1.0  1.000000\n",
      "39                      1.0      1.0     1.0  1.000000\n",
      "40                      1.0      1.0     1.0  1.000000\n",
      "41                      1.0      1.0     1.0  1.000000\n"
     ]
    }
   ],
   "source": [
    "xl_Topsis = pd.ExcelFile(\"Fuzzy TOPSIS rankings_5%.xlsx\")\n",
    "res_Topsis = len(xl_Topsis.sheet_names)\n",
    "print(\"Total no. of weightages: \",res_Topsis)\n",
    "print(\"\\n\")\n",
    "\n",
    "Topsis_lst = Topsis.iloc[:,-1].to_list()\n",
    "\n",
    "col_1_topsis = []\n",
    "col_2_topsis = []\n",
    "col_3_topsis = []\n",
    "col_4_topsis = []\n",
    "for i in range(1, res_Topsis+1):\n",
    "    Topsis_lst_1 = np.array(Topsis_lst[:])\n",
    "    topsis_wts_inc_5 = pd.read_excel(\"Fuzzy TOPSIS rankings_5%.xlsx\", sheet_name = \"topsis_rank\"+str(i)+\"_5\")\n",
    "    topsis_wts_inc_5 = list(topsis_wts_inc_5.iloc[:,-1])\n",
    "    topsis_wts_inc_10 = pd.read_excel(\"Fuzzy TOPSIS rankings_10%.xlsx\", sheet_name = \"topsis_rank\"+str(i)+\"_10\")\n",
    "    topsis_wts_inc_10 = list(topsis_wts_inc_10.iloc[:,-1])\n",
    "    topsis_wts_dec_5 = pd.read_excel(\"Fuzzy TOPSIS rankings_-5%.xlsx\", sheet_name = \"topsis_rank\"+str(i)+\"_-5\")\n",
    "    topsis_wts_dec_5 = list(topsis_wts_dec_5.iloc[:,-1])\n",
    "    topsis_wts_dec_10 = pd.read_excel(\"Fuzzy TOPSIS rankings_-10%.xlsx\", sheet_name = \"topsis_rank\"+str(i)+\"_-10\")\n",
    "    topsis_wts_dec_10 = list(topsis_wts_dec_10.iloc[:,-1])\n",
    "    \n",
    "  \n",
    "    x_arr = Topsis_lst_1\n",
    "    \n",
    "    y_arr = np.array(topsis_wts_inc_5)\n",
    "    r_5_inc = np.corrcoef(x_arr,y_arr)\n",
    "    col_1_topsis.append(r_5_inc[0][1])\n",
    "\n",
    "    y_arr = np.array(topsis_wts_inc_10)\n",
    "    r_10_inc = np.corrcoef(x_arr,y_arr)\n",
    "    col_2_topsis.append(r_10_inc[0][1])\n",
    "   \n",
    "    y_arr = np.array(topsis_wts_dec_5)\n",
    "    r_5_dec = np.corrcoef(x_arr,y_arr)\n",
    "    col_3_topsis.append(r_5_dec[0][1])\n",
    "    \n",
    "    y_arr = np.array(topsis_wts_dec_10)\n",
    "    r_10_dec = np.corrcoef(x_arr,y_arr)\n",
    "    col_4_topsis.append(r_10_dec[0][1])\n",
    "    \n",
    "PC_Topsis = pd.DataFrame()\n",
    "PC_Topsis[\"Inc 5%\"] = col_1_topsis\n",
    "PC_Topsis[\"Inc 10%\"] = col_2_topsis\n",
    "PC_Topsis[\"Dec 5%\"] = col_3_topsis\n",
    "PC_Topsis[\"Dec 10%\"] = col_4_topsis\n",
    "PC_Topsis[\"Weightage Increased\"] = list(range(1, res_Topsis+1))\n",
    "PC_Topsis = PC_Topsis.set_index(\"Weightage Increased\")\n",
    "\n",
    "print(PC_Topsis)\n",
    "PC_Topsis.to_excel(\"Topsis Sensitivity Results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of weightages:  17\n",
      "\n",
      "\n",
      "                     Inc 5%  Inc 10%  Dec 5%  Dec 10%\n",
      "Weightage Increased                                  \n",
      "1                       1.0      1.0     1.0      1.0\n",
      "2                       1.0      1.0     1.0      1.0\n",
      "3                       1.0      1.0     1.0      1.0\n",
      "4                       1.0      1.0     1.0      1.0\n",
      "5                       1.0      1.0     1.0      1.0\n",
      "6                       1.0      1.0     1.0      1.0\n",
      "7                       1.0      1.0     1.0      1.0\n",
      "8                       1.0      1.0     1.0      1.0\n",
      "9                       1.0      1.0     1.0      1.0\n",
      "10                      1.0      1.0     1.0      1.0\n",
      "11                      1.0      1.0     1.0      1.0\n",
      "12                      1.0      1.0     1.0      1.0\n",
      "13                      1.0      1.0     1.0      1.0\n",
      "14                      1.0      1.0     1.0      1.0\n",
      "15                      1.0      1.0     1.0      1.0\n",
      "16                      1.0      1.0     1.0      1.0\n",
      "17                      1.0      1.0     1.0      1.0\n"
     ]
    }
   ],
   "source": [
    "xl_AHP = pd.ExcelFile(\"AHP rankings_%5.xlsx\")\n",
    "res_AHP = len(xl_AHP.sheet_names)\n",
    "print(\"Total no. of weightages: \",res_AHP)\n",
    "print(\"\\n\")\n",
    "\n",
    "AHP_lst = AHP.iloc[:,-1].to_list()\n",
    "\n",
    "col_1_AHP = []\n",
    "col_2_AHP = []\n",
    "col_3_AHP = []\n",
    "col_4_AHP = []\n",
    "for i in range(1, res_AHP+1):\n",
    "    AHP_lst_1 = np.array(AHP_lst[:])\n",
    "    AHP_wts_inc_5 = pd.read_excel(\"AHP rankings_%5.xlsx\", sheet_name = \"ahp_rank\"+str(i)+\"_5\")\n",
    "    AHP_wts_inc_5 = list(AHP_wts_inc_5.iloc[:,-1])\n",
    "    AHP_wts_inc_10 = pd.read_excel(\"AHP rankings_%10.xlsx\", sheet_name = \"ahp_rank\"+str(i)+\"_10\")\n",
    "    AHP_wts_inc_10 = list(AHP_wts_inc_10.iloc[:,-1])\n",
    "    AHP_wts_dec_5 = pd.read_excel(\"AHP rankings_-5%.xlsx\", sheet_name = \"ahp_rank\"+str(i)+\"_-5\")\n",
    "    AHP_wts_dec_5 = list(AHP_wts_dec_5.iloc[:,-1])\n",
    "    AHP_wts_dec_10 = pd.read_excel(\"AHP rankings_-10%.xlsx\", sheet_name = \"ahp_rank\"+str(i)+\"_-10\")\n",
    "    AHP_wts_dec_10 = list(AHP_wts_dec_10.iloc[:,-1])\n",
    "    \n",
    "  \n",
    "    x_arr = AHP_lst_1\n",
    "    y_arr = np.array(AHP_wts_inc_5)\n",
    "    r_5_inc = np.corrcoef(x_arr,y_arr)\n",
    "    col_1_AHP.append(r_5_inc[0][1])\n",
    "   \n",
    "    x_arr = AHP_lst_1\n",
    "    y_arr = np.array(AHP_wts_inc_10)\n",
    "    r_10_inc = np.corrcoef(x_arr,y_arr)\n",
    "    col_2_AHP.append(r_10_inc[0][1])\n",
    "    \n",
    "    x_arr = AHP_lst_1\n",
    "    y_arr = np.array(AHP_wts_dec_5)\n",
    "    r_5_dec = np.corrcoef(x_arr,y_arr)\n",
    "    col_3_AHP.append(r_5_dec[0][1])\n",
    "    \n",
    "    x_arr = AHP_lst_1\n",
    "    y_arr = np.array(AHP_wts_dec_10)\n",
    "    r_10_dec = np.corrcoef(x_arr,y_arr)\n",
    "    col_4_AHP.append(r_10_dec[0][1])\n",
    "    \n",
    "PC_AHP = pd.DataFrame()\n",
    "PC_AHP[\"Inc 5%\"] = col_1_AHP\n",
    "PC_AHP[\"Inc 10%\"] = col_2_AHP\n",
    "PC_AHP[\"Dec 5%\"] = col_3_AHP\n",
    "PC_AHP[\"Dec 10%\"] = col_4_AHP\n",
    "PC_AHP[\"Weightage Increased\"] = list(range(1, res_AHP+1))\n",
    "PC_AHP = PC_AHP.set_index(\"Weightage Increased\")\n",
    "\n",
    "print(PC_AHP)\n",
    "PC_AHP.to_excel(\"AHP Sensitivity Results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCORDANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of weightages:  17\n",
      "\n",
      "\n",
      "                       Inc 5%   Inc 10%    Dec 5%   Dec 10%\n",
      "Weightage Increased                                        \n",
      "1                    0.836364  0.836364  0.842857  0.842857\n",
      "2                    0.836364  0.836364  0.836364  0.836364\n",
      "3                    0.836364  0.836364  0.836364  0.836364\n",
      "4                    0.836364  0.836364  0.836364  0.836364\n",
      "5                    0.836364  0.836364  0.836364  0.836364\n",
      "6                    0.842857  0.842857  0.836364  0.836364\n",
      "7                    0.842857  0.846753  0.836364  0.836364\n",
      "8                    0.836364  0.842857  0.836364  0.836364\n",
      "9                    0.836364  0.836364  0.836364  0.836364\n",
      "10                   0.836364  0.836364  0.836364  0.836364\n",
      "11                   0.836364  0.836364  0.836364  0.836364\n",
      "12                   0.836364  0.836364  0.836364  0.836364\n",
      "13                   0.836364  0.836364  0.842857  0.842857\n",
      "14                   0.836364  0.836364  0.836364  0.835065\n",
      "15                   0.836364  0.836364  0.833766  0.833766\n",
      "16                   0.842857  0.840260  0.836364  0.836364\n",
      "17                   0.836364  0.836364  0.842857  0.842857\n"
     ]
    }
   ],
   "source": [
    "xl_conc = pd.ExcelFile(\"Concordance rankings_%5.xlsx\")\n",
    "res_conc = len(xl_conc.sheet_names)\n",
    "print(\"Total no. of weightages: \",res_conc)\n",
    "print(\"\\n\")\n",
    "\n",
    "conc_lst = Concordance.iloc[:,-1].to_list()\n",
    "\n",
    "col_1_conc = []\n",
    "col_2_conc = []\n",
    "col_3_conc = []\n",
    "col_4_conc = []\n",
    "for i in range(1, res_conc+1):\n",
    "    conc_lst_1 = np.array(conc_lst[:])\n",
    "    conc_wts_inc_5 = pd.read_excel(\"Concordance rankings_%5.xlsx\", sheet_name = \"conc_rank\"+str(i)+\"_5\")\n",
    "    conc_wts_inc_5 = list(conc_wts_inc_5.iloc[:,-1])\n",
    "    conc_wts_inc_10 = pd.read_excel(\"Concordance rankings_%10.xlsx\", sheet_name = \"conc_rank\"+str(i)+\"_10\")\n",
    "    conc_wts_inc_10 = list(conc_wts_inc_10.iloc[:,-1])\n",
    "    conc_wts_dec_5 = pd.read_excel(\"Concordance rankings_-5%.xlsx\", sheet_name = \"conc_rank\"+str(i)+\"_-5\")\n",
    "    conc_wts_dec_5 = list(conc_wts_dec_5.iloc[:,-1])\n",
    "    conc_wts_dec_10 = pd.read_excel(\"Concordance rankings_-10%.xlsx\", sheet_name = \"conc_rank\"+str(i)+\"_-10\")\n",
    "    conc_wts_dec_10 = list(conc_wts_dec_10.iloc[:,-1])\n",
    "    \n",
    "  \n",
    "    x_arr = conc_lst_1\n",
    "    \n",
    "    y_arr = np.array(conc_wts_inc_5)\n",
    "    r_5_inc = np.corrcoef(x_arr,y_arr)\n",
    "    col_1_conc.append(r_5_inc[0][1])\n",
    "   \n",
    "    y_arr = np.array(conc_wts_inc_10)\n",
    "    r_10_inc = np.corrcoef(x_arr,y_arr)\n",
    "    col_2_conc.append(r_10_inc[0][1])\n",
    "    \n",
    "    y_arr = np.array(conc_wts_dec_5)\n",
    "    r_5_dec = np.corrcoef(x_arr,y_arr)\n",
    "    col_3_conc.append(r_5_dec[0][1])\n",
    "    \n",
    "    y_arr = np.array(conc_wts_dec_10)\n",
    "    r_10_dec = np.corrcoef(x_arr,y_arr)\n",
    "    col_4_conc.append(r_10_dec[0][1])\n",
    "    \n",
    "PC_conc = pd.DataFrame()\n",
    "PC_conc[\"Inc 5%\"] = col_1_conc\n",
    "PC_conc[\"Inc 10%\"] = col_2_conc\n",
    "PC_conc[\"Dec 5%\"] = col_3_conc\n",
    "PC_conc[\"Dec 10%\"] = col_4_conc\n",
    "PC_conc[\"Weightage Increased\"] = list(range(1, res_conc+1))\n",
    "PC_conc = PC_conc.set_index(\"Weightage Increased\")\n",
    "\n",
    "print(PC_conc)\n",
    "PC_conc.to_excel(\"Concordance Sensitivity Results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
